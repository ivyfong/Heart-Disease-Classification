---
title: "Heart Disease Classification Analysis - Ivy Fong"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, message=FALSE}
#load packages to be used
library(glmnet)
library(pROC)
library(class)
library(epiR)
library(tree)
```
```{r, include=FALSE}
#set working directory 
setwd("C:/Users/ivyfo/Dropbox/Master of Public Health/Master of Public Health - Courses/Fall 2018 - Courses/CHL7001 - Machine Learning/CHL7001 - Assignments/CHL7001 A2")
```     
```{r, results="hide"}
#load data and create dataset d without missing values and where V14<=1 is class 1, V14=0 is class 0
d <- read.table("cleveland.txt", header=F, sep=",", na.strings="?") #read txt data into R, specify no variable names, field separator character = ",", return ? for missing values
d <- na.omit(d) #only keep observations with complete information

#encode categorical variables as factors
d$V2 <- as.factor(d$V2) #encode V2 as a factor
d$V3 <- as.factor(d$V3) #encode V3 as a factor
d$V6 <- as.factor(d$V6) #encode V6 as a factor
d$V7 <- as.factor(d$V7) #encode V7 as a factor
d$V9 <- as.factor(d$V9) #encode V9 as a factor
d$V11 <- as.factor(d$V11) #encode V11 as a factor
d$V12 <- as.factor(d$V12) #encode V12 as a factor
d$V13 <- as.factor(d$V13) #encode V13 as a factor
d$V14 <- factor(ifelse(d$V14 <1, 0, 1), levels = c(1,0)) #encode V14 as a factor and specify classes

#name variables
names(d) <- c("age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", "oldpeak", "slope", "ca", "thal", "num")
summary(d) #print summary of d dataset
```

#Objective A - Assess the performance of three different classification methods
##Classification Method 1 - Logistic regression with ridge regression regularization
```{r, results="hide"}
x <- model.matrix(num~.,d)[,-1] #specify the predictor variables V1-13
y <- d$num #specify the outcome variable V14 (num)

train.I <- sample(nrow(d),round(nrow(d)*2/3)) #split data into train and test
train.data <- d[train.I,] #specify training dataset
test.data <- d[-train.I,] #specify test dataset
train.x <- model.matrix(num~.,train.data)[,-1] #specify training x
test.x <- model.matrix(num~.,test.data)[,-1] #specify test x
train.y <- train.data$num #specify training y
test.y <- test.data$num #specify test y

cv.rr <- cv.glmnet(train.x, train.y, family="binomial", alpha=0, nfolds=10) #perform 10-fold cross-validation 
cv.rr$lambda.min #print the lambda associated with the min MSE 
  
pred.rr <- predict(cv.rr, newx=test.x, s=cv.rr$lambda.min, type="class") #create an object with the predicted classes using the the lambda associated with the min MSE 
t.rr <- table(pred.rr, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t.rr) #calculate sensitivity and specificity
#1 - optimal lambda = 0.03839479, sensitivity = 0.15, specificity = 0.19
#2 - optimal lambda = 0.0322885, sensitivity = 0.08, specificity = 0.26
#3 - optimal lambda = 0.04334681, sensitivity = 0.13, specificity = 0.21
#4 - optimal lambda = 0.04483221, sensitivity = 0.10, specificity = 0.29
#5 - optimal lambda = 0.03916323, sensitivity = 0.15, specificity = 0.17
```

##Classification Method 2 - K-nearest neighbors
```{r, results="hide"}
x <- model.matrix(num~.,data=d)[,-1] #specify the predictor variables V1-13
x <- scale(x) #standardize the predictor variables to make things comparable
y <- d$num #specify the outcome variable V14 (num)

train.I <- sample(nrow(d),round(nrow(d)*2/3)) #split data into train and test
train.data <- d[train.I,] #specify training dataset
test.data <- d[-train.I,] #specify test dataset
train.x <- model.matrix(num~.,train.data)[,-1] #specify training x
test.x <- model.matrix(num~.,test.data)[,-1] #specify test x
train.y <- train.data$num #specify training y
test.y <- test.data$num #specify test y

#KNN (k=1)
pred.knn <- knn(train.x, test.x, train.y, k=1) #create an object with the predicted classes
t <- table(pred.knn, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t) 
#1 - sensitivity = 0.56, specificity = 0.60
#2 - sensitivity = 0.60, specificity = 0.60
#3 - sensitivity = 0.60, specificity = 0.55
#4 - sensitivity = 0.56, specificity = 0.55
#5 - sensitivity = 0.60, specificity = 0.55

#KNN (k=5)
pred.knn <- knn(train.x, test.x, train.y, k=5) #create an object with the predicted classes
t <- table(pred.knn, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t) 
#1 - sensitivity = 0.51, specificity = 0.60
#2 - sensitivity = 0.77, specificity = 0.50
#3 - sensitivity = 0.56, specificity = 0.64
#4 - sensitivity = 0.54, specificity = 0.62
#5 - sensitivity = 0.70, specificity = 0.57

#KNN (k=10)
pred.knn <- knn(train.x, test.x, train.y, k=10) #create an object with the predicted classes
t <- table(pred.knn, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t) 
#1 - sensitivity = 0.65, specificity = 0.57
#2 - sensitivity = 0.81, specificity = 0.48
#3 - sensitivity = 0.60, specificity = 0.64
#4 - sensitivity = 0.63, specificity = 0.72 
#5 - sensitivity = 0.78, specificity = 0.53

#KNN - Final - Choose k based on highest sensitivity and specificity
pred.knn <- knn(train.x, test.x, train.y, k=10) #create an object with the predicted classes
t.knn <- table(pred.knn, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t.knn) #calculate sensitivity and specificity
#1 - chosen k = 10, sensitivity = 0.58, specificity = 0.55
#2 - chosen k = 10, sensitivity = 0.81, specificity = 0.50
#3 - chosen k = 10, sensitivity = 0.65, specificity = 0.61
#4 - chosen k = 10, sensitivity = 0.61, specificity = 0.62
#5 - chosen k = 10, sensitivity = 0.72, specificity = 0.61
```

##Classification Method 3 - Classification tree
```{r, results="hide"}
x <- model.matrix(num~.,d)[,-1] #specify the predictor variables V1-13
y <- d$num #specify the outcome variable V14 (num)

train.I <- sample(nrow(d),round(nrow(d)*2/3)) #split data into train and test

train.data <- d[train.I,] #specify training dataset
test.data <- d[-train.I,] #specify test dataset
train.x <- model.matrix(num~.,train.data)[,-1] #specify training x
test.x <- model.matrix(num~.,test.data)[,-1] #specify test x
train.y <- train.data$num #specify training y
test.y <- test.data$num #specify test y

cfit <- tree(num~.,train.data) #fit the classification tree
cv.res <- cv.tree(cfit, FUN=prune.tree, method="misclass", K=5) #use cross-validation to generate the pruned tree with the FUN=prune.tree argument; parameter k (not related to the k number of folds) = alpha 
cv.res$size[which.min(cv.res$dev)] #print the size (number of terminal nodes) that minimizes the misclassification error = 6
cfit.pruned <- prune.misclass(cfit, best=cv.res$size[which.min(cv.res$dev)]) #using the prune.misclass function, prune the tree with the optimal size 

pred.c <- predict(cfit.pruned, newdata=test.data, type="class") #create an object with the predicted classes
t.c <- table(pred.c, test.y)[2:1,2:1] #create confusion matrix of predicted class vs. true class
epi.tests(t.c) #calculate sensitivity and specificity
#1 - optimal size = 6, sensitivity = 0.79, specificity = 0.62
#2 - optimal size = 9, sensitivity = 0.90, specificity = 0.70
#3 - optimal size = 7, sensitivity = 0.89, specificity = 0.74
#4 - optimal size = 6, sensitivity = 0.84, specificity = 0.80
#5 - optimal size = 7, sensitivity = 0.76, specificity = 0.78
```

#Objective B - Train a model that can be used for classification of future observations
##Chosen Method - Classification tree
```{r, results="hide"}
x <- model.matrix(num~.,d)[,-1] #specify the predictor variables V1-13
y <- d$num #specify the outcome variable V14 (num)

cfit <- tree(num~.,d) #fit the classification tree
plot(cfit) #plot the decision tree
text(cfit, pretty=0) #add text to the decision tree
title(main="Unpruned Classification Tree") #add title

cv.res <- cv.tree(cfit, FUN=prune.tree, method="misclass", K=5) #use cross-validation to generate the pruned tree with the FUN=prune.tree argument; parameter k (not related to the k number of folds) = alpha 
cv.res$size[which.min(cv.res$dev)] #print the size (number of terminal nodes) that minimizes the misclassification error = 6
cfit.pruned <- prune.misclass(cfit, best=cv.res$size[which.min(cv.res$dev)]) #using the prune.misclass function, prune the tree with the optimal size 
plot(cfit.pruned) #plot the pruned decision tree
text(cfit.pruned, pretty=0) #add text to the decision tree
title(main="Pruned Classification Tree")
```
  